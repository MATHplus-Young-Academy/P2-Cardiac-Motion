{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fabb8789-a4e1-4e30-8b10-91b94bbcd604",
   "metadata": {},
   "source": [
    "# PART 1 : SEGMENTATION + NOISE ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9549ccd-e544-4105-9a1c-dbd0b48f3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import data_augmentation\n",
    "from NN_segmentation.tst_dataset import cardiacdata\n",
    "from NN_segmentation.UNET3D_D4 import UNet3D\n",
    "from NN_segmentation.Auto3D_D4 import Auto3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a2b21f-00f0-4cc7-9a9d-31e4c81b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "path_data = r\"/home/jovyan/project_data/ACDC-Daten\"\n",
    "add_noise = True\n",
    "single_noise_probability = 50\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "\n",
    "for root, _, files in os.walk(path_data):\n",
    "    if os.path.isfile(os.path.join(root, \"image.nii.gz\")):\n",
    "        try:\n",
    "            data_list.append(cardiacdata(img_dir=os.path.join(root, \"image.nii.gz\"), label_dir=os.path.join(root, \"label.nii.gz\")))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "data_noise = []#copy.deepcopy(data_list)\n",
    "for i in range(len(data_list)):\n",
    "    noisy_data = []\n",
    "    for j in range(data_list[i].img.shape[0]):\n",
    "        for k in range(data_list[i].img.shape[1]):\n",
    "            noisy_data.append(data_augmentation.augmentation(np.squeeze(data_list[i].img[j,k,:,:]), single_noise_probability))\n",
    "    data_noise.append(np.array(noisy_data).reshape(data_list[i].img.shape))\n",
    "    \n",
    "data_noisy_list = copy.deepcopy(data_list)\n",
    "for i in range(len(data_list)):\n",
    "    data_noisy_list[i].img = data_noise[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c703477c-c4b5-4e82-9f0a-d63517a279cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for num in range(len(data_list)):\n",
    "#    fig, axes = plt.subplots(1, 2)\n",
    "#    axes[0].imshow(np.squeeze(data_list[num].img[0,0,:,:]), cmap=\"gray\")\n",
    "#    axes[0].axis(\"off\")\n",
    "#    axes[1].imshow(np.squeeze(data_noisy_list[num].img[0,0,:,:]), cmap=\"gray\")\n",
    "#    axes[1].axis(\"off\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f9c318-cde7-4583-bc61-ecad8aa7b99f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 7.80 GiB total capacity; 6.71 GiB already allocated; 59.44 MiB free; 6.82 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (img, seg_gt) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tst_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     30\u001b[0m     img, seg_gt \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcuda(), seg_gt\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 31\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     _, pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pred, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#pred, _ = torch.max(pred, 1)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/P2-Cardiac-Motion/NN_segmentation/Auto3D_D4.py:134\u001b[0m, in \u001b[0;36mAuto3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_start(x)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_convs):\n\u001b[0;32m--> 134\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_convs):\n\u001b[1;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m module(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/P2-Cardiac-Motion/NN_segmentation/Auto3D_D4.py:41\u001b[0m, in \u001b[0;36mDsBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 41\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#before_pool = out\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py:572\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    570\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, _triple(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    571\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 7.80 GiB total capacity; 6.71 GiB already allocated; 59.44 MiB free; 6.82 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# RUN SEGMENTATION\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "MDL_PATH=r\"/home/jovyan/project_segmentation_models/19\"\n",
    "data = data_list\n",
    "#data = data_noisy_list\n",
    "\n",
    "\n",
    "# network\n",
    "net = Auto3D(num_classes=4, in_channels=1, depth=4, start_filts=32, res=False).cuda()\n",
    "#net = Auto3D(num_classes=4, depth=4, start_filts=32, in_channels=1, res=True).cuda()\n",
    "\n",
    "net.load_state_dict(torch.load(os.path.join(MDL_PATH, \"model_best.pth.tar\"))['state_dict'])\n",
    "\n",
    "normOrg_list=[]\n",
    "normGT_list=[]\n",
    "normSeg_list=[]\n",
    "normError_list = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    tst_loader = DataLoader(data[i], batch_size=1, shuffle=False, num_workers=0)\n",
    "    img_shape = data[i].img.shape\n",
    "    normOrg=np.zeros((1,img_shape[1],img_shape[2],img_shape[3]),dtype=np.float32)\n",
    "    normGT=np.zeros((1,img_shape[1],img_shape[2],img_shape[3]),dtype=np.int16)\n",
    "    normSeg=np.zeros((1,img_shape[1],img_shape[2],img_shape[3]),dtype=np.int16)\n",
    "    #dice = np.zeros((1, 3))\n",
    "    net.eval()\n",
    "    for step, (img, seg_gt) in enumerate(tst_loader, 0):\n",
    "        img, seg_gt = img.cuda(), seg_gt.cuda()\n",
    "        pred = net(img)\n",
    "        _, pred = torch.max(pred, 1)\n",
    "        #pred, _ = torch.max(pred, 1)\n",
    "\n",
    "        pred = pred.squeeze().detach().cpu().numpy().astype(np.int8)\n",
    "        img = img.squeeze().detach().cpu().numpy()\n",
    "        gt = seg_gt.squeeze().detach().cpu().numpy().astype(np.int8)\n",
    "        #for j in range(3):\n",
    "        #    dice[step, j] = dice_comp(pred==j+1, gt==j+1)\n",
    "        normOrg[step]=img\n",
    "        normGT[step]=gt\n",
    "        normSeg[step]=pred\n",
    "\n",
    "    normOrg=np.reshape(normOrg,[int(normOrg.shape[1]/8),8,144,144])\n",
    "    normGT=np.reshape(normGT,[int(normGT.shape[1]/8),8,144,144])\n",
    "    normSeg=np.reshape(normSeg,[int(normSeg.shape[1]/8),8,144,144])\n",
    "    normError=np.abs(normGT.astype(np.float32)-normSeg.astype(np.float32))\n",
    "    normOrg=normOrg-normOrg.min()\n",
    "    \n",
    "    normOrg_list.append(normOrg)\n",
    "    normGT_list.append(normGT)\n",
    "    normSeg_list.append(normSeg)\n",
    "    normError_list.append(normError)\n",
    "\n",
    "\n",
    "#%% Display the output images\n",
    "index = 0\n",
    "for dispind in range(normOrg[index].shape[0]):\n",
    "    plot= lambda x: plt.imshow(x,cmap=plt.cm.gray,interpolation='bilinear')\n",
    "    plot1= lambda x: plt.imshow(x,interpolation='bilinear')\n",
    "    plt.clf()\n",
    "    plt.subplot(141)\n",
    "    plot(np.abs(normOrg[index][dispind,vol_slice,:,:]))\n",
    "    plt.axis('off')\n",
    "    plt.title('Original')\n",
    "    plt.subplot(142)\n",
    "    plot1(np.abs(normGT[index][dispind,vol_slice,:,:]))\n",
    "    plt.axis('off')\n",
    "    plt.title('True labels')\n",
    "    plt.subplot(143)\n",
    "    plot1(np.abs(normSeg[index][dispind,vol_slice,:,:]))\n",
    "    plt.axis('off')\n",
    "    plt.title('Segmentation')\n",
    "    plt.subplot(144)\n",
    "    plot(np.abs(normError[index][dispind,vol_slice,:,:]))\n",
    "    plt.title('Error')\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0,wspace=.01)\n",
    "    plt.show()\n",
    "# purple=0, blue=1, green=2, yellow=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105ab7c-953e-4a0e-9725-c319d07e345e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
